import re
import os
import json
from unstructured.partition.md import partition_md
from unstructured.cleaners.core import clean_extra_whitespace
from dotenv import load_dotenv
import os 
from openai import OpenAI 
from agentic_doc.parse import parse


class DynamicDocumentProcessor:
    def __init__(self, output_folder):
        self.output_folder = output_folder
        # 1. ÙƒÙ„Ù…Ø§Øª Ø«Ø§Ø¨ØªØ© Ù„Ù„Ø£ÙˆØµØ§Ù Ø§Ù„Ø¨ØµØ±ÙŠØ© (Ù…Ø³ØªØ®Ù„ØµØ© Ù…Ù† ØªØ¬Ø§Ø±Ø¨Ùƒ)


        self.static_image_noise = [
            "Visual Elements", "Technical Details", "Logo Elements",
            "Design & Placement", "Graphic Elements", "Spatial Relationships",
            "Analysis :", "Summary :", "Logo uses", "Stylized star",
            "blue and green lines", "central arrow", "wavy circular shape",
            "logo: No visible company name", "logo:", "Placement & Dimensions :", 
            "Text Elements :", "Design & Layout :", "Layout :","Design Elements :","Design Details :", 
            "Text Fields :", "Colour Palette :", "Spatial Relationships :","Dimensions & Placement :",
            "Design & Colour : ","Primary colour:","The use of blue and green", 
            "bilingual text indicates","national symbolism","Surrounding Outline :","Layout & Placement :"
                
            
    ]
        self.static_blacklist = [
                "ÙƒØ±Ø§Ø³Ø© Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ù…ÙˆØ§ØµÙØ§Øª",
                "Ù†Ù…ÙˆØ°Ø¬ ÙƒØ±Ø§Ø³Ø© Ø§Ù„Ø´Ø±ÙˆØ·",
                "Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ Ø¨Ù…ÙˆØ¬Ø¨ Ù‚Ø±Ø§Ø± ÙˆØ²ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ©",
                "Ø±Ù‚Ù… Ø§Ù„Ù†Ø³Ø®Ø© : Ø§Ù„Ø£ÙˆÙ„Ù‰",
                "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØµØ¯Ø§Ø±",
                "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
                "Ø§Ø³Ù… Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© :",
                "Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ :",
                "Ø´Ø±ÙƒØ© ØªÙ…ÙƒÙŠÙ† Ù„Ù„ØªÙ‚Ù†ÙŠØ§Øª",
                "ØªØ§Ø±ÙŠØ® Ø·Ø±Ø­ Ø§Ù„ÙƒØ±Ø§Ø³Ø©:",
                
            ]

        

    def get_cleaning_rules(self, raw_md_text, client):
        """Ø§Ù„Ø¢Ù† Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØªØ±ÙƒÙŠØ² ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙŠØ¯Ø±Ø² Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù"""
        sample = raw_md_text[:3000]
        
        prompt = f"""
        Analyze this RFP sample and identify recurring 'Document Noise' specific to this file:
        - Specific headers/footers (e.g., Department names, Tender numbers).
        - Document metadata that repeats on every page.
        
        Return ONLY a JSON with: "excluded_headers" (list).
        Sample: {sample}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            response_format={ "type": "json_object" }
        )
        
        rules = json.loads(response.choices[0].message.content)
        print(f"ğŸ¯ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù: {rules}")
        return rules

    def clean_document(self, file_path, rules):
        elements = partition_md(filename=file_path)
        cleaned_text = []
        dynamic_hdr_keys = rules.get('excluded_headers', [])

        for element in elements:
            text = element.text.strip()
            if not text: continue
            
            # --- [ÙÙ„ØªØ± 1] Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª (Regex) ---
            # ÙŠØ­Ø°Ù Ø§Ù„Ø±ÙˆØ§Ø¨Ø· (etimad.sa) ÙˆØ§Ù„ÙˆÙ‚Øª (4:29 PM) ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙƒØ³ÙˆØ±Ø© (/25)
            if re.search(r'https?://\S+|(\d{1,2}:\d{2}\s?(AM|PM))|(/\d{2})', text):
                continue

            # --- [ÙÙ„ØªØ± 2] Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡ Ø§Ù„Ø«Ø§Ø¨ØªØ© ---
            if any(trash in text for trash in self.static_blacklist):
                continue
            
            # --- [ÙÙ„ØªØ± 3] Ø£ÙˆØµØ§Ù Ø§Ù„ØµÙˆØ± (image_keywords) ---
            if any(noise.lower() in text.lower() for noise in self.static_image_noise):
                continue
            
            # --- [ÙÙ„ØªØ± 4] Ø§Ù„Ù‡ÙŠØ¯Ø±Ø² Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù…Ù† Ø§Ù„Ù€ LLM ---
            if any(key in text for key in dynamic_hdr_keys):
                continue

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
            text = clean_extra_whitespace(text)

            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† (Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ù…Ù†Ø§ÙØ³Ø© ÙˆØ±Ù‚Ù… Ø§Ù„ÙƒØ±Ø§Ø³Ø© Ù„Ø£Ù†Ù‡Ø§ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‡Ø§Ù…Ø©)
            if text:
                heading_pattern = r'^(\d+[\s\.\-].*|^Ø§Ù„Ù…Ø§Ø¯Ø©\s+.*|^Ø§Ù„Ø¨Ù†Ø¯\s+.*)'
                if re.match(heading_pattern, text) and not text.startswith('#'):
                    text = f"## {text}"
                cleaned_text.append(text)

        return "\n\n".join(cleaned_text)


def run_full_cleaning_pipeline(pdf_input_path: str):
    """
    ØªØ£Ø®Ø° Ù…Ø³Ø§Ø± Ø§Ù„Ù€ PDF ÙˆØªØ¹ÙŠØ¯ Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ù€ Markdown Ø§Ù„Ù…Ù†Ø¸Ù Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹.
    """
    load_dotenv()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ÙƒØ§Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    base_folder = os.path.join(os.path.dirname(pdf_input_path), "processed")
    os.makedirs(base_folder, exist_ok=True)
    
    raw_md_path = os.path.join(base_folder, "raw_temp.md")
    final_md_path = os.path.join(base_folder, "RFP_Final_Cleaned.md")

    processor = DynamicDocumentProcessor(output_folder=base_folder)

    # 1. Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù€ Markdown Ø®Ø§Ù…
    results = parse([pdf_input_path]) 
    raw_content = results[0].markdown
    with open(raw_md_path, "w", encoding="utf-8") as f:
        f.write(raw_content)

    # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø°ÙƒÙŠØ§Ù‹
    dynamic_rules = processor.get_cleaning_rules(raw_content, client)

    # 3. Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    final_text = processor.clean_document(raw_md_path, dynamic_rules)
    with open(final_md_path, "w", encoding="utf-8") as f:
        f.write(final_text)

    return final_md_path