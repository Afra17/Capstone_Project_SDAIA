{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install crewai_tools crewai -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade crewai crewai_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8387bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all your components\n",
    "from crewai import Crew, Process, LLM\n",
    "#import agentops\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "#from datetime import datetime\n",
    "# Import your other agents from their respective files\n",
    "from Requirement_Scout_Agent1 import Extractor_agent\n",
    "\n",
    "#Key Needed\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"لم يتم العثور على GOOGLE_API_KEY. تأكد من إضافته لملف .env\")\n",
    "\n",
    "#LLM\n",
    "\n",
    "my_llm = LLM(\n",
    "    model=\"gemini/gemini-1.0-flash\", \n",
    "    api_key=os.environ.get(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "#main.py\n",
    "def main():\n",
    "    #from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "\n",
    "    # Initialize the search recommender\n",
    "    output_dir=r\"./Capstone_Project_SDAIA/src/outputs\"\n",
    "    Extractor= Extractor_agent(llm=my_llm, output_dir=output_dir)\n",
    "    \n",
    "\n",
    "    #context_dependency\n",
    "   \n",
    "    #knowledge_sources\n",
    "    \"\"\"about_file = \"ohay is a company that provides AI solutions to help websites refine their search and recommendation systems.\"\n",
    "    file_context = StringKnowledgeSource(\n",
    "        content=about_file\n",
    "    )\"\"\"\n",
    "\n",
    "    # Create the crew\n",
    "    crew = Crew(\n",
    "        agents=[\n",
    "            Extractor.get_agent,\n",
    "    \n",
    "        ],\n",
    "        tasks=[\n",
    "            Extractor.get_task,\n",
    "            \n",
    "        ],\n",
    "        process=Process.sequential,\n",
    "        max_rpm=1,\n",
    "        \n",
    "        #knowledge_sources=[file_context],  # Make sure company_context is defined\n",
    "        #memory=True\n",
    "    )\n",
    "    \n",
    "   \n",
    "    result = crew.kickoff()\n",
    "\n",
    "    print(\"=== RESULTS ===\")\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"لم يتم العثور على GOOGLE_API_KEY. تأكد من إضافته لملف .env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"unstructured[md]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agentic_doc.parse import parse\n",
    "\n",
    "# 1. تحديد المسارات\n",
    "pdf_path = r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\data\\request1.pdf\"\n",
    "output_folder = r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\data\\processed\"\n",
    "\n",
    "# إنشاء المجلد إذا لم يكن موجوداً\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 2. عملية التحويل\n",
    "print(\"جاري تحويل الملف من PDF إلى MD...\")\n",
    "results = parse([pdf_path])\n",
    "\n",
    "# 3. حفظ النتيجة كملف .md\n",
    "# نفترض أن results عبارة عن قائمة كائنات، نأخذ النص من العنصر الأول\n",
    "md_filename = \"request1_raw.md\"\n",
    "md_output_path = os.path.join(output_folder, md_filename)\n",
    "\n",
    "with open(md_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    # ملاحظة: تأكد من مخرجات مكتبة agentic_doc، عادة النص يكون في .text أو .markdown\n",
    "    f.write(results[0].markdown) \n",
    "\n",
    "print(f\"✅ تم حفظ الملف الخام في: {md_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd7d2a",
   "metadata": {},
   "source": [
    "clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ef464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تنظيف الملف بنجاح وحذف أوصاف الصور والروابط وأرقام الصفحات!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.cleaners.core import clean_extra_whitespace\n",
    "\n",
    "def auto_clean_with_unstructured(file_path):\n",
    "    # 1. تقسيم الملف إلى عناصر\n",
    "    elements = partition_md(filename=file_path)\n",
    "\n",
    "    cleaned_text = []\n",
    "\n",
    "    for element in elements:\n",
    "        text = element.text.strip()\n",
    "        \n",
    "        # --- الفلترة بناءً على بداية النص (أوصاف الصور واللوقو) ---\n",
    "        image_keywords = [\n",
    "            \"Summary :\", \"logo:\", \"Visible Elements :\", \"Placement & Dimensions :\", \n",
    "            \"Analysis :\", \"Graphic Elements :\", \"Text Elements :\", \"Design & Placement :\", \n",
    "            \"Design & Layout :\", \"Layout :\", \"Design Elements :\", \"Design Details :\", \n",
    "            \"Text Fields :\", \"Colour Palette :\", \"Spatial Relationships :\",\"Dimensions & Placement :\",\"/25, 4:29 PM\"\n",
    "        ]\n",
    "        \n",
    "        if any(text.startswith(key) for key in image_keywords):\n",
    "            continue \n",
    "\n",
    "        # --- الفلترة بناءً على وجود كلمات معينة (الترويسات والتذييلات) ---\n",
    "        excluded_headers = [\n",
    "            \"المملكة العربية السعودية\", \"كراسة الشروط\", \"تاريخ الإصدار\", \n",
    "            \"tenders.etimad.sa\", \"المعتمد بموجب قرار وزير المالية\",\"اسم المنافسة: \",\"رقم الكراسة: \",\"تاريخ طرح الكراسة :\"\n",
    "        ]\n",
    "        if any(key in text for key in excluded_headers):\n",
    "            continue\n",
    "\n",
    "        # --- تصحيح حذف أرقام الصفحات والروابط باستخدام Regex ---\n",
    "        # حذف أرقام الصفحات مثل 31/37\n",
    "        text = re.sub(r'\\d+/\\d+', '', text)\n",
    "        \n",
    "        # حذف أي رابط يبدأ بـ http (روابط منصة اعتماد)\n",
    "        text = re.sub(r'https?://\\S+', '', text)\n",
    "\n",
    "        # 4. تنظيف الفراغات الناتجة عن الحذف\n",
    "        text = clean_extra_whitespace(text)\n",
    "\n",
    "        # إضافة النص النظيف فقط إذا لم يصبح فارغاً بعد الحذف\n",
    "        if text.strip():\n",
    "            cleaned_text.append(text)\n",
    "\n",
    "    return \"\\n\\n\".join(cleaned_text)\n",
    "\n",
    "# --- التشغيل ---\n",
    "input_file = r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\data\\processed\\request1_raw.md\"\n",
    "final_content = auto_clean_with_unstructured(input_file)\n",
    "\n",
    "with open(\"request1_final_clean3.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_content)\n",
    "\n",
    "print(\"✅ تم تنظيف الملف بنجاح وحذف أوصاف الصور والروابط وأرقام الصفحات!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ca978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def clean_rfp_markdown(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # 1. حذف الروابط المتكررة الخاصة بمنصة اعتماد (التذييل)\n",
    "    # يبحث عن أي سطر يبدأ بـ https://tenders.etimad.sa\n",
    "    content = re.sub(r'https://tenders\\.etimad\\.sa\\S+', '', content)\n",
    "\n",
    "    # 2. حذف أرقام الصفحات المتكررة (مثل 2/37, 3/37...)\n",
    "    content = re.sub(r'\\d+/\\d+', '', content)\n",
    "\n",
    "    # 3. حذف التاريخ والوقت الذي يظهر في أعلى الصفحة (مثلاً: 5/1/25, 4:29 PM)\n",
    "    content = re.sub(r'\\d+/\\d+/\\d+,\\s+\\d+:\\d+\\s+[AP]M', '', content)\n",
    "\n",
    "    # 4. حذف النصوص الثابتة المتكررة (كراسة الشروط والمواصفات، المملكة العربية السعودية، إلخ)\n",
    "    static_texts = [\n",
    "        \"كراسة الشروط والمواصفات\",\n",
    "        \"المملكة العربية السعودية\",\n",
    "        \"إسم الإدارة\",\n",
    "        \"إسم النموذج\",\n",
    "        \"رقم النسخة\",\n",
    "        \"تاريخ الإصدار\",\n",
    "        \"رقم الكراسة\",\n",
    "        \"بيانات مكتب تحقيق الرؤية\"\n",
    "    ]\n",
    "    for text in static_texts:\n",
    "        content = content.replace(text, '')\n",
    "\n",
    "    # 5. حذف الصور/اللوقو (في المارك داون تكون عادة على شكل ![image](...))\n",
    "    content = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', content)\n",
    "\n",
    "    # 6. تنظيف الفراغات الزائدة والأسطر الفارغة الكثيرة التي نتجت عن الحذف\n",
    "    content = re.sub(r'\\n\\s*\\n', '\\n\\n', content)\n",
    "    \n",
    "    # حفظ الملف النظيف\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content.strip())\n",
    "\n",
    "    print(f\"✅ تم تنظيف الملف وحفظه في: {output_file_path}\")\n",
    "\n",
    "# --- طريقة الاستخدام ---\n",
    "input_path = r\"C:\\path\\to\\your\\original_file.md\"\n",
    "output_path = r\"C:\\path\\to\\your\\cleaned_file.md\"\n",
    "\n",
    "clean_rfp_markdown(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_toc_only(file_path, limit_lines=150):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = [next(f) for _ in range(limit_lines)]\n",
    "    return \"\".join(lines)\n",
    "\n",
    "# ثم نمرر هذا النص للـ Task مباشرة\n",
    "toc_content = read_toc_only(r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\Agents\\src\\data.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac762e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
