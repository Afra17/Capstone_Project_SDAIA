{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install crewai_tools crewai -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade crewai crewai_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8387bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all your components\n",
    "from crewai import Crew, Process, LLM\n",
    "#import agentops\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "#from datetime import datetime\n",
    "# Import your other agents from their respective files\n",
    "from Investigator_Agent2 import selected_agent\n",
    "from Requirement_Scout_Agent1 import Extractor_agent\n",
    "#Key Needed\n",
    "from openai import OpenAI\n",
    "load_dotenv()\n",
    "\n",
    "#LLM\n",
    "\n",
    "groq_llm = LLM(\n",
    "    model=\"groq/llama-3.1-8b-instant\",\n",
    "    temperature=0.1\n",
    ")\n",
    "groq_llm2 = LLM(\n",
    "    model=\"groq/llama-3.3-70b-versatile\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "openai_llm = LLM(\n",
    "    model=\"openai/gpt-4o-mini\", \n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "\n",
    "#main.py\n",
    "def main():\n",
    "    #from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "\n",
    "    # Initialize the search recommender\n",
    "    output_dir=r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\outputs\"\n",
    "    Extractor= Extractor_agent(llm=openai_llm, output_dir=output_dir)\n",
    "    \n",
    "\n",
    "    #context_dependency\n",
    "   \n",
    "    #knowledge_sources\n",
    "    \"\"\"about_file = \"ohay is a company that provides AI solutions to help websites refine their search and recommendation systems.\"\n",
    "    file_context = StringKnowledgeSource(\n",
    "        content=about_file\n",
    "    )\"\"\"\n",
    "\n",
    "    # Create the crew\n",
    "    crew = Crew(\n",
    "        agents=[\n",
    "            Extractor.get_agent,\n",
    "    \n",
    "        ],\n",
    "        tasks=[\n",
    "            Extractor.get_task,\n",
    "            \n",
    "        ],\n",
    "        process=Process.sequential,\n",
    "        max_rpm=1,\n",
    "        \n",
    "        #knowledge_sources=[file_context],  # Make sure company_context is defined\n",
    "        #memory=True\n",
    "    )\n",
    "    \n",
    "   \n",
    "    result = crew.kickoff()\n",
    "\n",
    "    print(\"=== RESULTS ===\")\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# تحميل المتغيرات من ملف .env\n",
    "load_dotenv()\n",
    "\n",
    "# استدعاء المفتاح\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# تمرير المفتاح للعميل\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70147b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "try:\n",
    "    host = socket.gethostbyname(\"api.groq.com\")\n",
    "    print(f\"Connection successful: {host}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_sections_content(md_file_path, selected_headings):\n",
    "    with open(md_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    extracted_data = {}\n",
    "    \n",
    "    # تقسيم الملف بناءً على العناوين (Headers) التي تبدأ بـ # أو ## أو ###\n",
    "    # سنبحث عن العناوين المختارة ونستخرج ما تحتها\n",
    "    for heading in selected_headings:\n",
    "        # نمط Regex للبحث عن العنوان وما بعده حتى العنوان التالي\n",
    "        # نستخدم re.escape للتعامل مع أي رموز خاصة في اسم العنوان\n",
    "        escaped_heading = re.escape(heading)\n",
    "        pattern = rf\"(^#+.*{escaped_heading}.*$\\n)([\\s\\S]*?)(?=\\n#+|$)\"\n",
    "        \n",
    "        match = re.search(pattern, content, re.MULTILINE | re.IGNORECASE)\n",
    "        if match:\n",
    "            extracted_data[heading] = match.group(2).strip()\n",
    "        else:\n",
    "            extracted_data[heading] = \"لم يتم العثور على محتوى لهذا القسم.\"\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a21760",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_titles = [\" الاستبعاد من المنافسة\",\" الموافقة على الشروط\"]\n",
    "filtered_context = get_sections_content(r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\Agents\\request1_final_clean3.md\", selected_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ac2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5d88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"لم يتم العثور على GOOGLE_API_KEY. تأكد من إضافته لملف .env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"unstructured[md]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agentic_doc.parse import parse\n",
    "\n",
    "# 1. تحديد المسارات\n",
    "pdf_path = r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\data\\request1.pdf\"\n",
    "output_folder = r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\data\\processed\"\n",
    "\n",
    "# إنشاء المجلد إذا لم يكن موجوداً\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 2. عملية التحويل\n",
    "print(\"جاري تحويل الملف من PDF إلى MD...\")\n",
    "results = parse([pdf_path])\n",
    "\n",
    "# 3. حفظ النتيجة كملف .md\n",
    "# نفترض أن results عبارة عن قائمة كائنات، نأخذ النص من العنصر الأول\n",
    "md_filename = \"request1_raw.md\"\n",
    "md_output_path = os.path.join(output_folder, md_filename)\n",
    "\n",
    "with open(md_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    # ملاحظة: تأكد من مخرجات مكتبة agentic_doc، عادة النص يكون في .text أو .markdown\n",
    "    f.write(results[0].markdown) \n",
    "\n",
    "print(f\"✅ تم حفظ الملف الخام في: {md_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd7d2a",
   "metadata": {},
   "source": [
    "clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ef464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.cleaners.core import clean_extra_whitespace\n",
    "\n",
    "def auto_clean_with_unstructured(file_path):\n",
    "    # 1. تقسيم الملف إلى عناصر\n",
    "    elements = partition_md(filename=file_path)\n",
    "\n",
    "    cleaned_text = []\n",
    "\n",
    "    for element in elements:\n",
    "        text = element.text.strip()\n",
    "        \n",
    "        # --- الفلترة بناءً على بداية النص (أوصاف الصور واللوقو) ---\n",
    "        image_keywords = [\n",
    "            \"Summary :\", \"logo:\", \"Visible Elements :\", \"Placement & Dimensions :\", \n",
    "            \"Analysis :\", \"Graphic Elements :\", \"Text Elements :\", \"Design & Placement :\", \n",
    "            \"Design & Layout :\", \"Layout :\", \"Design Elements :\", \"Design Details :\", \n",
    "            \"Text Fields :\", \"Colour Palette :\", \"Spatial Relationships :\",\"Dimensions & Placement :\",\"/25, 4:29 PM\",\"تاريخ طرح الكراسة: /1446\",\"/1446\"\n",
    "        ]\n",
    "        \n",
    "        if any(text.startswith(key) for key in image_keywords):\n",
    "            continue \n",
    "\n",
    "        # --- الفلترة بناءً على وجود كلمات معينة (الترويسات والتذييلات) ---\n",
    "        excluded_headers = [\n",
    "            \"المملكة العربية السعودية\", \"كراسة الشروط\", \"تاريخ الإصدار\", \n",
    "            \"tenders.etimad.sa\", \"المعتمد بموجب قرار وزير المالية\",\"اسم المنافسة: \",\"رقم الكراسة: \",\"تاريخ طرح الكراسة:\" ,\"/25, 4:29 PM\"\n",
    "        ]\n",
    "        if any(key in text for key in excluded_headers):\n",
    "            continue\n",
    "\n",
    "        # --- تصحيح حذف أرقام الصفحات والروابط باستخدام Regex ---\n",
    "        # حذف أرقام الصفحات مثل 31/37\n",
    "        text = re.sub(r'\\d+/\\d+', '', text)\n",
    "        \n",
    "        # حذف أي رابط يبدأ بـ http (روابط منصة اعتماد)\n",
    "        text = re.sub(r'https?://\\S+', '', text)\n",
    "\n",
    "        # 4. تنظيف الفراغات الناتجة عن الحذف\n",
    "        text = clean_extra_whitespace(text)\n",
    "\n",
    "        # إضافة النص النظيف فقط إذا لم يصبح فارغاً بعد الحذف\n",
    "        if text.strip():\n",
    "            cleaned_text.append(text)\n",
    "\n",
    "    return \"\\n\\n\".join(cleaned_text)\n",
    "\n",
    "# --- التشغيل ---\n",
    "input_file = r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\data\\processed\\request1_raw.md\"\n",
    "final_content = auto_clean_with_unstructured(input_file)\n",
    "\n",
    "with open(\"request1_final_clean3.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_content)\n",
    "\n",
    "print(\"✅ تم تنظيف الملف بنجاح وحذف أوصاف الصور والروابط وأرقام الصفحات!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_toc_only(file_path, limit_lines=145):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = [next(f) for _ in range(limit_lines)]\n",
    "    return \"\".join(lines)\n",
    "\n",
    "# ثم نمرر هذا النص للـ Task مباشرة\n",
    "toc_content = read_toc_only(r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\Agents\\request1_final_clean3.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toc_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def read_toc_to_json(file_path, output_json_path, limit_lines=145):\n",
    "    lines = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            # نقرأ الأسطر ونقوم بتنظيفها من الفراغات الزائدة\n",
    "            for _ in range(limit_lines):\n",
    "                line = next(f).strip()\n",
    "                if line: # نتجاهل الأسطر الفارغة تماماً لتقليل حجم الملف\n",
    "                    lines.append(line)\n",
    "    except StopIteration:\n",
    "        pass # انتهى الملف قبل الوصول للحد المحدد\n",
    "    except Exception as e:\n",
    "        print(f\"حدث خطأ أثناء القراءة: {e}\")\n",
    "        return None\n",
    "\n",
    "    # تشكيل هيكل البيانات للـ JSON\n",
    "    toc_data = {\n",
    "        \"document_name\": os.path.basename(file_path),\n",
    "        \"toc_lines\": lines  # هنا نضع القائمة\n",
    "    }\n",
    "\n",
    "    # حفظ الملف بصيغة JSON\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(toc_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"✅ تم استخراج الفهرس وحفظه في: {output_json_path}\")\n",
    "    return toc_data\n",
    "\n",
    "# --- طريقة الاستخدام ---\n",
    "input_md = r\"C:\\Users\\user\\OneDrive - University of Prince Mugrin\\سطح المكتب\\Capstone_Project_SDAIA\\src\\Agents\\request1_final_clean3.md\"\n",
    "output_json = \"toc_extracted.json\"\n",
    "\n",
    "# تشغيل الدالة\n",
    "toc_content = read_toc_to_json(input_md, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b899c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
