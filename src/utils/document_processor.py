import os
import re
import json
from agentic_doc.parse import parse
from unstructured.partition.md import partition_md
from unstructured.cleaners.core import clean_extra_whitespace

class DocumentProcessor:
    def __init__(self, output_folder):
        self.output_folder = output_folder
        if not os.path.exists(self.output_folder):
            os.makedirs(self.output_folder)

    def process_pdf_to_clean_md(self, pdf_path):
        """
        Ø§Ù„Ù…Ù‡Ù…Ø©: ØªØ­ÙˆÙŠÙ„ PDF Ø¥Ù„Ù‰ MD Ø«Ù… ØªÙ†Ø¸ÙŠÙÙ‡ ÙˆØ¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙÙŠ Ø®Ø·ÙˆØ© ÙˆØ§Ø­Ø¯Ø©.
        """
        file_base_name = os.path.basename(pdf_path).replace(".pdf", "")
        raw_md_path = os.path.join(self.output_folder, f"{file_base_name}_raw.md")
        final_md_path = os.path.join(self.output_folder, f"{file_base_name}_final_clean.md")

        # 1. Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„ (Parsing)
        print(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ {file_base_name} Ù…Ù† PDF Ø¥Ù„Ù‰ Markdown...")
        results = parse([pdf_path])
        raw_content = results[0].markdown

        with open(raw_md_path, "w", encoding="utf-8") as f:
            f.write(raw_content)

        # 2. Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠ (Cleaning & Repairing)
        print(f"ğŸ§¹ Ø¬Ø§Ø±ÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ ÙˆØ¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† (Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø¹Ù†ÙˆØ§Ù† 64)...")
        cleaned_content = self._auto_clean_logic(raw_md_path)

        with open(final_md_path, "w", encoding="utf-8") as f:
            f.write(cleaned_content)

        print(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©! Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø¸ÙŠÙ: {final_md_path}")
        return final_md_path

    def _auto_clean_logic(self, file_path):
        """Ù…Ù†Ø·Ù‚ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†"""
        elements = partition_md(filename=file_path)
        cleaned_text = []

        # ÙƒÙ„Ù…Ø§Øª Ù…Ø³ØªØ¨Ø¹Ø¯Ø© (Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØªØ±ÙˆÙŠØ³Ø§Øª)
        image_keywords = [
            "Summary :", "logo:", "Visible Elements :", "Analysis :", 
            "Graphic Elements :", "Design & Layout :", "/1446", "/25"
        ]
        excluded_headers = [
            "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©", "ÙƒØ±Ø§Ø³Ø© Ø§Ù„Ø´Ø±ÙˆØ·", "tenders.etimad.sa", 
            "Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ Ø¨Ù…ÙˆØ¬Ø¨ Ù‚Ø±Ø§Ø± ÙˆØ²ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "Ø§Ø³Ù… Ø§Ù„Ù…Ù†Ø§ÙØ³Ø©:", "Ø±Ù‚Ù… Ø§Ù„ÙƒØ±Ø§Ø³Ø©:"
        ]

        for element in elements:
            text = element.text.strip()
            
            # Ø§Ù„ÙÙ„ØªØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ¨Ø¹Ø¯Ø©
            if any(text.startswith(key) for key in image_keywords): continue 
            if any(key in text for key in excluded_headers): continue

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØ£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª
            text = re.sub(r'\d+/\d+', '', text)
            text = re.sub(r'https?://\S+', '', text)
            text = clean_extra_whitespace(text)

            if text.strip():
                # --- ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† (Fixing Heading 64 and others) ---
                # Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯: ÙŠØ¨Ø­Ø« Ø¹Ù† Ø±Ù‚Ù… ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ø·Ø± ÙŠØªØ¨Ø¹Ù‡ (Ø´Ø±Ø·Ø© Ø£Ùˆ Ù†Ù‚Ø·Ø© Ø£Ùˆ Ù…Ø³Ø§ÙØ©)
                # Ù…Ø«Ø§Ù„: "64 Ø¹Ù†ÙˆØ§Ù†" Ø£Ùˆ "64 - Ø¹Ù†ÙˆØ§Ù†" Ø£Ùˆ "64. Ø¹Ù†ÙˆØ§Ù†"
                heading_pattern = r'^(\d+[\s\.\-].*|^Ø§Ù„Ù‚Ø³Ù…\s+.*|^Ø§Ù„Ù…Ø§Ø¯Ø©\s+.*)'
                
                if re.match(heading_pattern, text):
                    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø³Ø·Ø± ÙŠØ­Ù…Ù„ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù† #ØŒ Ù†Ø¶ÙŠÙÙ‡Ø§ Ù„Ù‡
                    if not text.startswith('#'):
                        text = f"## {text}"
                
                cleaned_text.append(text)

        return "\n\n".join(cleaned_text)

# --- Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ù…Ù„ÙÙƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
if __name__ == "__main__":
    PDF_INPUT = r"C:\Users\user\...\data\request1.pdf"
    OUTPUT_DIR = r"C:\Users\user\...\data\processed"
    
    processor = DocumentProcessor(OUTPUT_DIR)
    final_file = processor.process_pdf_to_clean_md(PDF_INPUT)