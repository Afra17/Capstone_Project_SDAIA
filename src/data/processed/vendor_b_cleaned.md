مشروع: تطوير وتفعيل المساعد الذكي لأتمتة عملية جمع وتحليل بيانات مكتب تحقيق الرؤية

رقم الكراسة: ٥٨٣٠٠٠٠٠٢

الجهة الطالبة: شركة تمكين للتقنيات – شركة مساهمة غير مدرجة

نوع الوثيقة: **العرض التقني والمالي (Proposal)**

اسم المتقدم: [Vendor B]
تاريخ التقديم: 12/09/2025

النسخة: V1.0

1

جدول المحتويات
القسم الأول: المعلومات العامة
1.1 اسم المنافسة
1.2 رقم الكراسة
1.3 الجهة الطالبة

1.
القسم الثاني: العرض الفني
2. الملخص التنفيذي (Executive Summary)
3. أهداف المشروع
4. نطاق عمل المشروع (DETAILED)
5. النتائج المتوقعة (Deliverables)
6. البنية التقنية والمعمارية (VERY DEEP)
7. منهجية التنفيذ وإدارة المشروع
8. خطة تنفيذ المشروع (STEP-BY-STEP)
9. نموذج التنفيذ البياني أو الامتثال التنظيمي
10. إدارة المخاطر
11. إدارة الجودة وضمان الامتثال
12. الهيكل التنظيمي لفرق العمل
13. الجدول الزمني ومتطلبات التنفيذ
14. إدارة الوثائق ونقل المعرفة
15. نموذج الدعم والتشغيل (SLA)
16. موائمة المشروع مع رؤية المملكة 2030

1.
ملاحظة تنظيمية
2. منهجية التسعير
3. التسعير التفصيلي حسب المراحل
4. الملخص المالي الإجمالي
5. تأكيد شمولية التسعير
6. الالتزام بقواعد إعادة التسعير وصلاحيات لجنة فحص العروض
7. الإقرار بمبدأ المفاضلة السعرية وآلية فك التعادل

القسم الرابع: الإقرار الختامي
٤.١ الإقرار الختامي

القسم الأول: المعلومات العامة

١.١ اسم المنافسة
تطوير وتفعيل المساعد الذكي لأتمتة عملية جمع وتحليل بيانات مكتب تحقيق الرؤية

١.٢ رقم الكراسة

2

٢.......
٥ ٨ ٣

١.٣ الجهة الطالبة

شركة تمكين للتقنيات – شركة مساهمة غير مدرجة

القسم الثاني: العرض الفني

٢.١ الملخص التنفيذي (Executive Summary)
تتولى جهة الطلابة (مكتب تحقيق الرؤية) مسؤولية متابعة المبادرات والمشاريع ومؤشرات الأداء المرتبطة بالأهداف القطاعية السنوية،
وتقديم صورة دقيقة وموحدة للقيادة عن مستوى التقدم،
والانحرافات،
والمخاطر،
وأسباب التعثر والنجاح.
ونظراً لتعدد مصادر البيانات (أنظمة تشغيلية،
منصات مالية/موارد،
قواعد بيانات،
ملفات دورية،
ومستندات غير مهيكلة) تظهر تحديات جوهرية تشمل تكرار العمل،
تضارب الأرقام،
تأخر التقارير،
وضعف القدرة على التحليل المقارن والتنبؤ.

يتم [Vendor B] حالياً مؤسسياً عملياً لتطوير وتفعيل مساعد ذكي داخلي يحقق "مصدر الحقيقة الواحد" عبر أتمتة جمع البيانات (End-to-End)،
توحيدها والتحقق من جودتها،
ثم بناء طبقة تحليلات وصفية،
وتنبؤية قابلة للتفسير،
وإتاحة واجهة محادثة تحليلية (RAG) داخلية تجيب عن أسئلة القادة باللغة الطبيعية بشكل "مؤسس" قابل للتتبع إلى بيانات المستودع ونتائج الاستعلامات،
مع ضوابط تمنع توليد مخرجات غير قابلة للتدقيق.

- • تميز [Vendor B] التنافسي يتمثل في:
- • واقعية التنفيذ: تحويل النطاق إلى تدفقات تشغيل،
عقود تكامل(Contracts)،
قواعد جودة بيانات،
وخطة اختبار UAT/Pilot قابلة للتوقيع.
- • عمق البيانات والتحليلات: طبقة Semantic KPIs،
وإطار “Explainable Analytics” يربط النتائج بعوامل مؤثرة بلغة أعمال.
- • حوكمة وأمن متقدمين: مواءمة عملية مع ضوابط الأمن السيبراني الوطنية (NCA ECC) دون حشو،
مع IAM/MFA/RBAC تدقيق شامل (Auditability) وإقامة بيانات داخل المملكة.
- • استدامة وتسليم قابل للتطوير: تسليم كود مصدري عبر Git،
Runbooks،
أدلة تشغيل وصيانة وتطوير،
وخطة تسجيل لمدة العقد (18 شهر) ودعم 3 أشهر بعد الإطلاق وفق SLA بمؤشرات زمنية واضحة.

٢.٢ أهداف المشروع

الهدف (١): أنظمة جمع البيانات من مصادر متعددة End-to-End

- • ماذا: جمع بيانات المبادرات،
المشاريع،
و KPIs من مصادر داخلية متعددة وتوحيدها في نموذج بيانات مؤسسي موحد.
- • كيف:
 
1. بناء طبقة استيعاب (Data Ingestion) تدعم (API/DB Connectors/CSV-Excel/File): Landing Zone/PDF-Word extraction عند الحاجة.

## 3

-
2. تطبيق قواعد جودة (Validation + Standardization + Deduplication + Mapping) مع سجل أخطاء(Data Quality Log).
- 3. جدول تشغيل (Schedulers) وإدارة الاعتمادية بين المهام وإعادة المحاولة والتنبيه.
- • النتائج: تحديثات دورية/قريبة من اللحظي حسب المصدر،
مع مصدر حقيقة واحد.
- • معيار قبول/قياس: نسبة نجاح مهم الاستيعاب < 98% شهرياً،
وزمن اكتشاف فشل مهمة ≥ 10 دقائق،
وسجل أخطاء مصنفة مع إجراءات معالجة.

- • الهدف (٢): توفير رؤية موحدة للأداء وإتاحة الوصول الذاتي للمعلومة
- • ماذا: لوحات وتقارير موحدة ومحدثة باستمرار بمستويات صلاحيات.
- • كيف:
 
1. تصميم نموذج بيانات موحد (Canonical Data Model) + طبقة Semantic KPIs.
 
2. مستودع تحليلي (Data Warehouse/Lakehouse حسب بنية الجهة) لاستعلامات سريعة.
 
3. لوحات تنفيذية بمرشحات (Sector/Agency/Initiative/Time) وتصدير.
- • النتائج: مصدر حقيقة واحد لتقارير قابلة للتصدير.
- • معيار قبول/قياس: KPIs مع اعتماد قاموس بيانات رسمي،
وزمن تحميل للوحة القيادية ≥ ٥ ثوانٍ لسيناريوهات الاستعلام القياسية.

- • الهدف (3): التحليل الذكي للأداء (وصفياً وتنبؤياً) واكتشاف الانحرافات
- • ماذا: تحليل الانحرافات والاتجاهات والتنبؤ بالمخاطر/التأخير.
- • كيف:
 
- 1. محرك وصفي: Variance،
Trend؛
أسباب التغير،
مقارنة الفترات.
 
- 2. محرك تنبؤي: نماذج تصنيف/انحدار/سلاسل زمنية وفق طبيعة KPI مع قابلية تفسير.
 
- 3. محرك Exception Detection: عتبات / قواعد عمل Anomaly detection + ربطها بالتنبيهات.
- • النتائج: تنبيهات مبكرة أو توقعات قابلة للتفسير.
- • معيار قبول/قياس: تغطية 100% من KPIs المعتمدة بحسابات وصفية وقياسية،
واعتماد منهج تفسير Feature importance/SHAP-like explanations في تقارير التنبؤ.

- الهدف (٤): دعم اتخاذ القرار عبر مساعد محادثة تحليلي داخلي

- ماذا: مساعد داخلي يجيب عن استفسارات تحليلية وينتج جداول/رسوم/ملخصات.

- كيف:
 
- ١. تطبيق (RAG): Retriever (بيانات المستودع + وثائق تعريفية) ثم Generator ينتج إجابة “مؤسسة” بمرجع داخلي (IDs/Query results).
 
- ٢. طبقة NLP اللغة العربية والإنجليزية وربط الكيانات (Initiative/KPI/Owner/Date).
 
- ٣. تحسين الاستدلال (Inference Optimization): Cache + Context management + Answerability checks.

- النتائج: إجابات قابلة للتحقق مع مؤشرات “مرجعية” داخلية.
- معيار قبول/قياس: ٩٠٪ من أسئلة UAT القياسية يُجاب بإجابات صحيحة قابلة للتتبع،
ورفض آمن للأسئلة غير القابلة للإجابة (Safe refusal) عند نقص البيانات.

الهدف (٥): رفع الامتثال الأمني والحوكمة وضمان بقاء البيانات داخل المملكة

- ماذا: حوكمة وأمن شاملان للتخزين والنقل والوصول والتشغيل ضمن النطاق الجغرافي المصرح.
- كيف:

4

1.
تشفير AES-256 للتخزين و TLS 1.3 للنقل.
2. IAM + MFA + RBAC + Audit logs ومبدأ أقل الامتيازات.
3. خيارات استضافة: داخلي/سحابة خاصة/عامة ضمن المملكة وفق قرار الجهة.
 
- النتائج: امتثال موثّق وتدقيق قابل للمراجعة.
 
- معيار قبول/قياس: اجتياز مراجعة أمنية قبل الإطلاق (Go/No-Go Security Gate) وتوثيق إقامة البيانات ونتائج اختبارات الاختراق.

٢.٣ نطاق عمل المشروع (DETAILED)
٢.٣.١ المساعد الذكي التحليلي

القدرات الوظيفية (ماذا + كيف + ناتج + قبول:)

1.
الإجابة التحليلية الموجهة للقيادة
 
- • ماذا: إجابات عن حالة المبادرات،
أداء KPIs،
أسباب الانحراف،
المقارنات،
والتنبؤات.
 
- • كيف:
 ◦ تحويل السؤال إلى “Intent + Entities + Time range” ثم توليد استعلامات/قياسات (SQL/semantic queries).
 ◦ استرجاع النتائج + تعريفات KPI ذات العلاقة + قواعد الأعمال،
ثم توليد إجابة (RAG) مرتبطة بمخرجات الاستعلام فقط.
 
- النتائج: إجابة تنفيذية،
جدول داعم،
مؤشرات مرجعية داخلية (مثل Initiative_ID, KPI_ID, Query_Run ID).
 
- معيار قبول: كل إجابة في UAT تتضمن مرجعا داخليا للتتبع،
ولا تنتج أرقاما غير موجودة في المستودع.

-
2. تحويل الاستفسارات إلى مخرجات قابلة للتضمين

- • ماذا: إنتاج جداول/رسوم/نقاط تنفيذية يمكن إراجها في تقارير القيادة.
- • كيف: قوالب إخراج (Templates) للرسوم والجداول مع حفظ الاستعلام (Saved Queries) وصلاحيات الوصول.
- • النتائج: حزمة إخراج Export Pack (PDF/Excel/Image) “مرتبطة بآخر تحديث بيانات.
- • معيار قبول: إمكانية إعادة إنتاج التقرير بنفس النتائج عبر نفس Query_Run_ID.

-
٣. أمثلة استعلامات تنفيذية مدعومة (واقعية):
 
- "اعرض المبادرات المتأخرة أكثر من ١٤ يوماً في قطاع X خلال ٣٠ يوماً مع أسباب التأخر الأعلى تكراراً."
 
- "ما KPIs التي لديها انحراف سلبي متكرر ثلاث دورات قياس؟
وما المبادرات المرتبطة بها؟"
 
- "ما أعلى ١٠ مبادرات ذات عالية الأثر من حيث مؤشر المخاطر المركب؟
وما عوامل المخاطر؟"
 
- "توقع احتمالية عدم تحقيق مستهدف الربع القادم لمؤشر KPI-
### مع شرح أهم العوامل."

4.
إجراءات مقترحة وفق قواعد عمل متفق عليها
- ماذا: اقتراح إجراءات تصعيد/طلب تحديث/مراجعة خطة.
- كيف: بمحرك قواعد الأعمال يربط "نوع الاستثناء" بإجراء مقترح ومسار موافقة.

## 5

- • النتائج: توصية + سبب + خطوة تالية + جهة مالكة.
- • معيار قبول: اعتماد قاموس الاستثناءات والاجراءات من مكتب تحقيق الرؤية قبل التفعيل.

- • أنظمة داخلية لدعم القرار وإدارة المبادرات.
- • منصات/ERP مالية/موارد (مثل SAP/Oracle حسب المتاح).
- • ملفات دورية (Excel/CSV) وتقارير تشغيلية.
- • مستندات غير مهيكلة عند الحاجة (PDF/Word) بضوابط واضحة.

**(Ingestion Mechanisms): آليات الجمع**

APIs (REST/GraphQL)

1.
- • كيف: توثيق + Endpoint contracts مفاتيح خدمة + retries + Rate limiting.
- • ناتج: يسحب منتظم/لحظي حسب المصدر.
- • قبول: استدعاءات ناجحة ≤ 99% في بيئة الإنتاج،
مع تسجيل كامل للطلبات الحساسة.

2.
**DB Connectors**

- • **كيف:** حسابات خدمة للقراءة فقط،
شبكات معزولة،
Whitelisting،
و Query pushdown لتقليل الحمل.
- • **ناتج:** استخراج آمن وموثق.
- • **قبول:** عدم وجود صلاحيات كتابة،
وتوثيق نطاق الجداول/الحقول المستخرجة.

-
3. **Landing Zone للملفات**
 
- **كيف:** يفحص نوع الملف وتوقيعه،
يقيد حجم،
عزل (Quarantine) للملفات المخالفة،
ثم Parsing للملفات المخالفة.
 
- **نتائج:** ملفات مقبولة تدخل المعالجة.
 
- **قبول:** يسجل تدقيق لكل ملف.
(Uploader/Time/Checksum/Result)

-
4. معالجة الوثائق غير المهيكلة

 
- • كيف OCR/Parsing: عند الحاجة + استخراج حقول وفق قوالب + مراجعة بشرية للحالات الحرجة-Human-in-the-loop).
 
- • ناتج: حقول منظمة تُدخل إلى staging.
 
- • قبول: دقة استخراج ≤ 95% في عينة UAT،
مع تمييز السجلات التي تتطلب مراجعة.

- • منطق التحقق والتطبيق: (Data Quality Rules)
 
- • اكتمال الحقول الإلزامية.
(Initiative_ID, Owner_ID, Status, Dates, KPI_ID)
 
- • صلاحية القيم (نطاقات/وحدات/تواريخ).
 
- • منع التكرار (Dedup) بمفاتيح طبيعية/مصطنعة.

## 6

- • Mapping بين الأنظمة (Sector codes/Agency codes)
- • معيار قبول: تقرير جودة بيانات شهري يتضمن completeness/validity/uniqueness/timeliness مع خط أساس وتحسن مستهدف.

- • سجل أخطاء البيانات:(Data Quality Log)
- • نوع الخطأ،
المصدر،
السجل،
السبب،
الإجراء،
مستوى التصعيد،
وتاريخ الإغلاق.
- • معيار قبول 100% من الأخطاء تُسجل وتُصنف،
و90% من أخطاء P1 تُغلق خلال 5 أيام عمل بالتنسيق مع ملاك البيانات.

2.3.3 التحليل الذكي للأداء

- KPIs (KPI Tracking): تتبع
- • قاموس KPI: تعريف/وحدة/دورية/مستهدف/مصدر/مسؤول.
- • مقاييس قياسه Achievability score.
Trend slope.
Variance.
Actual vs Target.
- • معيار قبول: توقيع قاموس KPI وإغلاق أي تعارض تعريف قبل الإطلاق.

- • تحليل الاتجاهات:(Trend Analysis)
- • اختيار النماذج حسب طبيعة السلسلة (منتظمة/غير منتظمة/موسمية).
- • تتبع الضجيج،
وقياس عدم اليقين (Confidence bands) لمنع قرارات خاطئة.
- • معيار قبول: تقارير اتجاهات تتضمن "ثقة التوقع" وشرح مبسط للقيادة.

- • اكتشاف المخاطر والتأخير (Risk & Delay Detection):
 
- • مؤشر مخاطر مركب يعتمد على: التقدم مقابل الخطة،
تأخر التحديثات،
Dependencies،
تاريخ الانحرافات،
ضغط الموارد.
 
- • آليات Threshold-based + Anomaly detection + Probability prediction،
مع تفسير.
 
- • معيار قبول: قائمة استثناءات قابلة للمتبع + سبب واضح + توصية إجراء.

- • تحديد الاستثناءات: (Exception Identification)
 
- ◦ قواعد متفق عليها،
مثل:
 
- ◦ انحراف X% لعدد Y دورات
 
- ◦ توقف تحديث N أيام
 
- ◦ تعارض مصدرين لقياس واحد
 
- **معيار قبول:** اعتماد قواعد الاستثناء قبل تفعيل التنبيهات في الإنتاج.

٢.٣.٤ التقارير ولوحات التحكم
لوحات تنفيذية: (Executive Dashboards)

## 7

- • لوحة قيادية؛
ملخص الحالة،
أهم المخاطر،
KPIs حرجة،
قائمة الاستثناءات.
- • لوحة قطاع/إدارة؛
توزيع المبادرات،
الانحرافات،
أسباب التعثر.
- • لوحة مبادرة؛
تقدم،
KPIs مرتبطة،
مخاطر،
إجراءات.
- • خصائص: Filters/Drill-down/Export/Role-based views.
- • معيار قبول: قبول UAT للوحات عبر سيناريوهات اختبار مُمَرْقَة ومُوَقَّعة.

- • تقارير دورية: (Periodic Reports)
- • أسبوعي/شهري: الإنجاز،
الانحراف،
التعثر،
توصيات.
- • تقارير اجتماعات القادة: قالب ثابت + (PDF) جداول مرفقة.
- • معيار قبول: توليد تلقائي وفق جدول زمني،
مع ختم "تاريخ آخر تحديث بيانات".

- • تحليل حسب الطلب: (Ad-hoc Analysis)
- • عبر واجهة التحليلات أو المساعد.
- • حفظ الاستعلامات المتكررة مع صلاحيات.
- • معيار قبول: إمكانية إعادة تشغيل الاستعلام وإظهار نفس النتائج لنفس إصدار البيانات.

٥.٣.٢ التكامل مع الأنظمة القائمة

- • استراتيجية: API (API Gateway)
- • توحيد الدخول عبر (API Gateway) داخلي،
سياسات.
(Rate limiting/Auth/Audit logs)
- • توثيق العقود (Contracts) وإدارة النسخ.
(Versioning)
- • معيار قبول،
وثائق API موقعة + اختبارات تكامل ناجحة لكل مصدر.

- • تبادل البيانات:(Data Exchange)
- • Batch لمعظم الأنظمة كبديلة لضمان الاستقرار،
مع Near-real-time للمصادر الحرجة عند توفر الأحداث.
- • تنسيقات JSON/CSV أو XML عند الحاجة.
- • معيار قبول: يتحقق من اتساق المعرفات وتوثيق نقاط التحويل.(Adapters)

- • التشغيل البيني: (Interoperability)
- • نموذج بيانات موحد + Master Data mapping.
- • معيار قبول: عدم وجود تضارب معرفات بين الأنظمة بعد تطبيق الـ Mapping

٣.٣.٦ متطلبات الأمن السيبراني والحوكمة

- • التحكم بالوصول: (Access Control)
- • أدوار: قيادة/محلل أداء/مالك مبادر/مشرف نظام.

## 8

- + Least privilege + RBAC تفويض حسب القطاع/المبادرة.
- معيار قبول: بمصفوفة صلاحيات (Role-Entitlement Matrix) معتمدة.

- • تسجيل الدخول،
الاستعلامات الحساسة،
تغييرات القواعد والنماذج.
- • ربط السجلات بمنصة مراقبة مركزية (SIEM) إن توفرت.
- • معيار قبول: اختبار تدقيق يظهر “من فعل ماذا ومتى” دون فجوات.

- • تصنيف البيانات: (Data Classification)
- • تشغيلية/داخلية/سرية،
وضوابط على التصدير/الطباعة/المشاركة.
- • معيار قبول: تطبيق سياسات/DLP قيود التصدير حسب التصنيف.

٢.٤ النتائج المتوقعة (Deliverables)

يتم تسليم المخرجات وفق مراحل التنفيذ وبصيغة قبول رسمية (محاضر توقيع/استلام) من ممثل الجهة،
مع ربط كل مخرج بمعايير قبول قابلة للقياس.

-
١) تقرير الوضع الحالي والفجوات (مرحلة التخطيط والتحليل)
 
- الوصف: تحليل الوضع الراهن لمصادر البيانات،
تدفقات التقارير،
الفجوات التقنية والتنظيمية،
جودة البيانات،
وتوصيات.
 
- النطاق التفصيلي:
 
- ◦ خارطة مصادر + (Source Catalog) مالك البيانات + طريقة الوصول.
 
- ◦ تحليل جودة (DQ baseline) ومشكلات التضارب والتكرار.
 
- ◦ فجوات التكامل / أولويات المصادر (P1/P2/P3).
 
- ◦ خارطة طريق (Roadmap) مرتبطة بخطة ١٨ شهراً.
 
- معايير القبول: تقرير معتمد وموثق،
ويشمل قائمة مصادر نهائية + مؤشرات جودة خط أساس + خطة معالجة واضحة.

-
٢) (نماذج تجربة المستخدم الأولية (Prototypes) مرحلة التصميم)
 
- • الوصف: نماذج تفاعلية للوحات وواجهة المحادثة،
ومركز التقارير.
 
- • النطاق: يشمل لوحات قيادية (Executive)،
قطاع/إدارة،
مبادرة،
Chat،
KPI،
 
- • معايير القبول: جلسات اختبار قابلية استخدام (Usability) وتوثيق ملاحظات وإغلاقها واعتماد النماذج.

-
٣) خطة الربط وأمن البيانات (مرحلة التصميم)
- • الوصف: وثيقة تصميم التكامل والأمن.
(Interfaces, IAM, MFA, Logging, Data residency)
- • النطاق: عقود وواجهات التكامل،
سياسات التغيير،
خطة اختبارات أمنية،
مصفوفة صلاحيات.
- • معايير القبول: مراجعة أمنية،
واعتماد خطي،
وتحديد نقاط التكامل وتوزيع الأدوار مع الجهة.

٤) تطوير الوحدات الأساسية (مرحلة التطوير والاختبار)

## 9

- • الوصف: بناء وتشغيل وحدات Data Ingestion؛
التحليل الوصفي،
التقارير،
واجهة المحادثة التحليلية(RAG)،
Semantic KPIs.
- • طبقة:
- • النطاق:
 
- ◦ تشغيل ingestion لمصادر P1 المتفق عليها.
 
- ◦ مستودع تحليلي + نمذجة بيانات Semantic layer +
 
- ◦ لوحات قيادية/قطاع/مصادر + مركز تقارير.
 
- ◦ RAG مربوط بالمستودع و الوثائق التعريفية.
- • معايير القبول: نجاح التكامل مع مصادر P1،
وتحقيق مؤشرات الأداء المتفق عليها (الزمن/الدقة/الاستقرار).

- • تقرير الاختبارات الشاملة (مرحلة التطوير والاختبار)
- • الوصف: نتائج Unit/Integration/System/Performance/Security + UAT/Pilot.
- • النطاق: خطط اختبار،
حالات اختبار،
نتائج،
عيوب،
إعادة اختبار،
مؤشرات جودة.
- • معايير القبول: توقيع محضر اجتياز UAT/Pilot وخطة معالجة ملاحظات نهائية.

-
٦) تسليم دليل الاستخدام والتقارير (مرحلة النشر والدعم)
 
- • الوصف: وثائق الاستخدام والتشغيل والصيانة + تسليم الكود المصدري عبر Git + وثائق API.
 
- • النطاق: User Guide،
Runbook،
Developer Guide،
Data Model Docs،
DR Instructions،
API Docs،
سجل إصدارات.
 
- • معايير القبول: تسليم كامل عبر القنوات المعتمدة،
ونقل حقوق الملكية الفكرية،
وإتاحة سجل تاريخي للتعديلات.

- • مخرجات إضافية ضمن نطاق التسليم والتوثيق والتدريب والدعم:
- • مواد تدريبية + جلسات تدريب للمستخدمين الرئيسيين.
- • إعداد بيانات + خطة Dev/Test/Prod/DR DR واختبارات استعادة.
- • دعم تشغيلي لمدة 3 أشهر بعد النشر مع تقارير أداء شهرية.

٥.٢ البنية التقنية والمعمارية (VERY DEEP)

١, ٥, ٢ نظرة عامة على المعمارية (طبقات منطقية)

يعتمد الحل على معمارية طبقية قابلة للتوسع تفصل المسؤوليات وتضمن الاستدامة:
- • Data Sources Layer
- • Ingestion & Integration Layer
- • Storage & Processing Layer
- • AI/ML & Analytics Layer
- • Business Logic & Governance Layer
- • Visualization & Reporting Layer
- • Security, Observability & Operations Layer

مبدأ تصميم محوري: كل رقم/مؤشر يظهر في لوحة أو إجابة محادثة يجب أن يكون ناتجاً من استعلام قابل للتدقيق مرتبط بإصدار بيانات محدد.
(Data Version)

10

٢.٥.٢ طبقة جمع البيانات (Data Ingestion Layer)

- • المكونات:
- • Connectors/Adapters لكل نظام.
- • Landing Zone للملفات (فحص/عزل/تحقق).
- • Orchestration/Scheduling لإدارة الجداول و الاعتمادية (DAG).
- • Validation Engine لقواعد الجودة.
- • Metadata Catalog للتعريف المصادر و الحقول و التحولات.

**(Workflow): تدفق العمل**

1.
Extract (API/DB/File)
2. Schema validation + Constraints
3. Transform → Canonical model
4. Curated/Warehouse→Load → Staging
5. Logs + Alerts + Data Quality Log

- • قرارات تصميم عملية:
- • البدء بـ Batch لضمان الاستقرار،
ثم تفعيل مسارات Near-real-time للمصادر الحرجة عند توفرها.
- • فصل Staging عن Curated لمنع انتقال بيانات غير مكتملة للوحات.

- • مؤشرات تشغيل: (Operability KPIs)
- • نجاح تشغيل Jobs،
زمن التنفيذ،
حجم البيانات،
عدد الأخطاء حسب النوع،
متوسط وقت الإصلاح.

٣،
٥،
٢ طبقة التخزين والتحضير (Storage & Processing Layer)

- • Staging Store: بيانات خام + نتائج تحقق + سجلات أخطاء.
- • Curated Store/Data Warehouse: بيانات موحدة للمبادرات و KPIs.
- • Semantic Layer: تعريف المقاييس القياسية ومنطق احتسابها.
(KPI as Code)

- • Data Versioning) إصدار بيانات لكل دورة تحميل.
- • Retention policies وفق التصنيف.
- • Lineage: تتبع مصدر كل حقل وتحوله.

معيار قبول: تقرير Lineage يوضح “من أين جاء هذا الرقم؟” من المصدر حتى اللوحة.

11

٤،
٥،
٢ طبقة الذكاء الاصطناعي والتحليلات (AI/ML & Analytics Layer)

- • مكوّن RAG التحليلي: (Retrieval-Augmented Generation)
- • Retriever: يسترجع:
 
- ◦ نتائج استعلامات من المستودع التحليلي (KPIs/States/Trends/Exceptions)
 
- ◦ وثائق داخلية: تعريف KPI،
سياسات متابعة،
قاموس اسباب التعثر
- • Ranker: يرتب النتائج حسب الصلة
- • Generator: لتوليد إجابة مفيدة بما تم استرجاعه فقط
- • Grounding: إرفاق مراجع داخلية (KPI_ID/Initiative_ID/Query_Run_ID/Data_Version)

ضوابط منع الهلوسة: (Answerability Controls)
- إذا لم يوجد دليل كافٍ في البيانات/الوثائق:
 ◦ يقوم النظام برد "غير قابل للإجابة حالياً" مع سبب (نقص بيانات/صلاحيات/فترة زمنية غير متاحة) + اقتراح ما يلزم لتوفير الإجابة.

- • تحسين الاستدلال (Inference Optimization):
- • Cache للاستعلامات المتكررة + تخزين ملخصات KPI.
- • Context window management: ضغط سياق/اختيار أعلى أذنة.
- • حدود حمولة (Payload) للاستعلامات الثقيلة مع مسارات بديلة.
(Asynchronous report generation)

- • التحليل التنبؤي:
 
- • اختيار نماذج وفق حالة الاستخدام:
 ◦ Classification لاحتمالية التأخير/عدم تحقيق المستهدف
 ◦ Time-series للتوقعات ربع/شهري حسب دورية القياس
 
- • قابلية تفسير شرط: عرض أهم العوامل بلغة أعمال.

- • ضمن نطاق المشروع MLOps-lite:
 
- • Model registry مبسط (نسخة/بيانات تدريب/مقاييس/تاريخ)
 
- • Monitoring لانحراف الأداء + إعادة تقييم دورية
 
- • Retraining policy عند توفر بيانات جديدة (وفق موافقة الجهة)
 
- • معيار قبول: تقرير نموذج يوضح بيانات التدريب،
المقاييس،
التفسير،
و حدود الاستخدام.

- ٥،
٢ طبقة منطق الأعمال والحوكمة (Business Logic Layer)
- • محرك قواعد الأعمال: عتبات/انحراف/تصعيد/إشعارات/قاموس أسباب الحذر.
- • IAM/RBAC أو سياسات التصيد والمشاركة.
- • مسارات اعتماد: قوالب تقارير،
تغييرات قواعد الأعمال.

## 12

- • معيار قبول: اعتماد "قواعد الأعمال كوثيقة" قبل Go-Live وتطبيقها كمتحكم مركزي.
- ٦،
٥،
٢ طبقة العرض والتقارير (Visualization & Reporting Layer)
- • واجهة ويب داخلية آمنة: لوحات تفاعلية + صفحات مبادرة + KPI/مركز تقارير + واجهة محادثة.
- • محرك تقارير: قوالب PDF دورية + تقارير حسب الطلب.
- • UX:تصميم متجاوب + WCAG + اختبار قابلية استخدام.
- • معيار قبول: نجاح سيناريوهات UAT للقيادة ومكتب تحقيق الرؤية.

- • ٢،
٥،
٧ طبقة التكامل (Integration Layer)
- • API Gateway + Service contracts + Versioning.
- • Event hooks مستقبليّة عند توفّر event buses.
- • معيار قبول: اختبارات تكامل موثّقة لكل مصدر P1.

٨،
٥،
٢ البنية التحتية والبيينات (Dev/Test/Prod/DR)

**الخيارات المدعومة:** داخلي/سحابة خاصة/سحابة عامة داخل المملكة حسب قرار الجهة.
تصميم البنية:

- • Dev: بيانات وهمية/مقننة
- • Test/Pilot: عينة بيانات فعلية
- • Prod: سياسات أمنية مشددة
- • DR: نسخ احتياطي مشفر + RPO/RTO متفق عليه + اختبارات استعادة

- • قرارات تصميم:
- • Network segmentation بين الطبقات
- • Secrets Management
- • ادخال بيئة معتمدة CI/CD
- • معيار قبول: نجاح اختبار DR وفق RPO/RTO المتفق عليه وتوثيق نتائجه.

٢,٦ منهجية التنفيذ وإدارة المشروع

١, ٦, ٢ نموذج التنفيذ

اعتماد منهجيّةٍ رشيقةٍ (Agile) مع حوكمةٍ حكوميّةٍ واضحةٍ.

## 13

- • Backlog معتمد ومنتج
- • تسليمات مرحلة قابلة للقياس
- • اجتماعات مراجعة (Sprint Reviews) مع أصحاب المصلحة
- • ضبط نطاق عبر Change Control

**معيار قبول**: كل متطلب مرتبط بحالة اختبار ومخرج قابل للتسليم.
(Traceability)

- ٢،
٦،
٢ آليات الإطلاق التدريجي

- • Iterative Releases: إصدار MVP ثم توسعات.
- • Pilot Deployment قبل الإطلاق النهائي لاختبار: التكامل،
قابلية الاستخدام،
دقة التحليلات.
- • معيار قبول: بمحضر Pilot يحدد ما تم اعتماده وما تبقى للإغلاق قبل Go-Live.

- ٣،
٢،
٦ إشراك أصحاب المصلحة
- • لجنة توجيهية (Steering) تضم مكتب تحقيق الرؤية والجهات ذات العلاقة.
- • ورش تعريف KPI ومصادر البيانات.
- • جلسات UAT وقياس رضا المستخدم.
- • معيار قبول: بمحاضر ورش واعتمادات رسمية للقياس والقواعد.

- • ٤،
٦،
٢ نقاط الحوكمة (Governance Checkpoints)
- • اعتماد المتطلبات
- • اعتماد التصميم المعماري/الأمني
- • اعتماد خطة الاختبارات
- • بوابة جاهزية الإطلاق Go/No-Go
- • الاستلام النهائي
- • **معيار قبول:** عدم الانتقال لمرحلة دون توقيع نقطة الحوكمة.

٢.٧ خطة تنفيذ المشروع (STEP-BY-STEP)

مدة العقد ١٨ شهراً تشمل التنفيذ والتشغيل المرحلي،
بالإضافة إلى ٣ أشهر دعم بعد النشر كما هو موضح.

1،
7،
2،
1 المرحلة 1: تحليل المتطلبات والوضع الراهن (Requirements Analysis)

الأهداف تثبيت المصادر،
فهم الفجوات،
تحديد مؤشرات النجاح والقبول.
الأنشطة (خطوات عملية):

1.
مقابلات + ورش.(KPI definitions, Owners, Reporting cycles)
2. جرد المصادر وتحديد P1/P2/P3 مع قرار نمط التكامل لكل مصدر.
3. تقييم جودة بيانات (DQ baseline) وقياس التضارب.

14

4.
صياغة نموذج بيانات أولي + قاموس كيانات.
(Initiative/KPI/Owner/Risk)
المخرجات: تقرير الوضع الحالي والفجوات + سجل متطلبات + خطة تكامل أولية.
معايير القبول: اعتماد قائمة مصادر P1 وتعريفات KPI الأساسية وتوقيع محضر مرحلة التحليل.

٢،٧،٢ المرحلةُ 2: التصميم (Solution Design)

**الأهداف:** تصميم UX/UI،
المعمارية،
التكامل،
الأمن.
**الأنشطة:**
1. تصميم Prototypes للوحات و الـ Chat ومسارات المستخدم.
2. تصميم نموذج البيانات النهائي + Semantic layer.
3. تصميم IAM/MFA/RBAC + Audit + Data residency.
4. تصميم عقود التكامل (Contracts) وخطة اختبار الأمن والتكامل.

**المخرجات:** نماذج UX/UI معتمدة + وثيقة معمارية + خطة الربط وأمن البيانات.
**معايير القبول:** اعتماد النماذج والوثائق عبر لجنة التوجيه.

٣،
٢،
٧،
٣ المرحلة ٣: التطوير والإعداد (Development & Configuration)

الأهداف: بناء الوحدات الأساسية وتجهيز البينات.
الأنشطة:

1.
تطوير ingestion لمصادر P1 + Landing zone + DQ rules + Catalog.
2. بناء المستودع التحليلي،
ETL/ELT + Semantic KPIs.
3. تطوير لوحات وتقارير أساسية (قيادية/قطاع/مبادرة).
4. بناء RAG وربطه بالمستودع والوثائق التعريفية مع ضوابط answerability.
5. إعداد CI/CD + مراقبة وتشغيل (Observability).

المخرجات MVP: داخلي + تكاملات + P1 لوحات أساسية،
نسخة أولى للمساعد.

معايير القبول: نجاح تكامل P1،
وتحقق مؤشرات الأداء الأساسية،
وتوثيق التشغيل.

٢،
٧،
٤ المرحلة ٤: الاختبارات وضمان الجودة (Testing & QA)

الأهداف: جاهزية وظيفية/أمنية/إدارية وتنفيذ Pilot.
الأنشطة:

- • Unit/Integration/System tests
- • Performance tests (Load/Stress) فوق سيناريوهات قياسية
- • Security testing اختبارات اختراق دورية
- + UAT مع المستخدمين الرئيسيين + Pilot
- إغلاق الملاحظات وإعادة الاختبار

المخرجات: تقرير الاختبارات الشاملة + محضر اجتياز UAT/Pilot

معايير القبول: توقيع UAT بنسبة نجاح حالات الاختبار < 95% وإغلاق عيوب P1/P2.

هـ ٢،
٧،
٥: المرحلة ٥: النشر والإطلاق (Deployment & Go-Live)

الأهداف: نشر Prod/DR وتشغيل فعلي مستقر.
الأنشطة:

## 15

- • تجهيز Prod/DR
- • ترحيل إعدادات التكامل
- • تفعيل المراقبة والتنبيهات
- • تنفيذ خطة Go-Live وإدارة التغيير
- • المخرجات: نظام عامل في الإنتاج + محضر إطلاق.
- • معايير القبول: تحقق الاستقرار خلال فترة المراقبة الأولية،
وتفعيل SLA.

٦،
٧،
٢،
٦ المرحلة: التدريب ونقل المعرفة (Training & Knowledge Transfer)

**الأهداف:** تمكين فريق الجهة للتشغيل و الصيانة و التطوير.
**الأنشطة:**

- • تدريب المستخدمين (قادة/محللين/ملاك مبادرات)
- • تدريب تقني لفرق التحول الرقمي/الدعم (Runbooks, ETL, rules, RAG ops)
- • ورش تشغيل ingestion وإدارة القواعد والنماذج

المخرجات: مواد تدريبية + أدلة تشغيل وصيانة.

معايير القبول: اجتياز تقييم تدريب (اختبار/سيناريوهات تشغيل) واعتماد محضر نقل معرفة.

٧،
٧،
٢،
٧ المرحلة ٧: التشغيل والدعم ٣ – (Operations & Support) أشهر بعد النشر

**الأهداف:** استقرار التشغيل ومعالجة البلاغات والتحسينات العاجلة.

**الأنشطة:**
- • مركز دعم وفق SLA
- • تقارير أداء شهرية
- • تحسينات ضمن نطاق الدعم

**المخرجات:** تقارير دعم شهرية + سجل البلاغات + مؤشرات SLA.

**معايير القبول:** الالتزام بمؤشرات الاستجابة/المعالجة المتفق عليها.

٢.٨ الأمن السيبراني والامتثال التنظيمي

يلتزم [Vendor B] بموائمة الأمن السيبراني مع الضوابط الوطنية ذات العلاقة،
وبالخصوص متطلبات الضوابط الأساسية للأمن السيبراني (NCA ECC) من حيث الحوكمة،
إدارة الوصول،
حماية البيانات،
السجلات،
وإدارة الثغرات،
بما يتناسب مع بيئة الجهة ودرجة التصنيف.

- ضوابط أساسية (ماذا + كيف + قبول):
 
- • الإقامة البيانية داخل المملكة: خيارات استضافة داخلية/سحابة حماية ضمن المملكة،
وتوثيق موقع المعالجة.
قبول: تقرير إقامة بيانات موقع قبل Go-Live.
 
- • IAM + MFA + RBAC: تكامل مع هوية الجهة (OAuth2/SAML حسب البيئة)،
ومصفوفة صلاحيات معتمدة؛
قبول: اختيار صلاحيات يثبت منع الوصول غير المصرح.
 
- • التشفير AES-256: للتخزين وTLS 1.3 للنقل وإدارة مفاتيح آمنة (KMS/Secrets).
قبول: فحوصات أمنية تؤكد التفعيل.

## 16

- • Logging & Monitoring: سجل مركزي،
تنبيهات،
وربط SIEM عند توفره.
قبول سيناريو تدقيق منفذ وموثّق.
- • اختبارات اختراق دورية: قبل الإطلاق وبعده وفق خطة.
قبول: تقرير معالجة الثغرات الحرجة،
وإغلاقها قبل Go-Live.
- • الخصوصية وحماية البيانات الشخصية: تطبيق مبدأ أقل قدر من البيانات،
وضوابط تصدير/مشاركة حسب التصنيف.
قبول: اعتماد سياسات مشاركة/تصدير.

2.9 إدارة المخاطر

يطبق [Vendor B] إدارة مخاطر عمليةٍ مصفوفةٍ مختصرةٍ يتم تحديثها دورياً،
مع مالك لكل خطر وخطةٍ تخفيفٍ ومؤشر إنذار مبكر.

مصفوفة مخاطر مختصرة (خطر/أثر/احتمال/تخفيف/مؤشر):

1.
تعقيد التكامل مع أنظمة متعددة أثر: تأخير الجدول / احتمال: متوسط

- • تخفيف،
تثبيت P1 مبكرًا + Contracts + بيئة تكامل + اختبار مبكر / مؤشر: فشل تكامل متكرر 3 حزمات أسبوعيًا.

2.
تضارب تعريفات KPI بين الإدارات / أثر: فقد ثقة القيادة / احتمال: مرتفع

- • تخفيف: قاموس KPI معتمد + Semantic layer + لجنة تعريفات / مؤشر.
اختلاف قيمة KPI لنفس الفترة بين مصدرين.

3.
جودة بيانات منخفضة/نقص تحديثات بياناتك / أثر: تحليلات غير موثوقة / احتمال: متوسط
 • تخفيف + DQ rules + Data Quality Log: مسار تصعيد لمالكي البيانات / مؤشر: completeness < 95%.

4.
مخاطر أمنية/صلاحيات زائدة / أثر: اختراق/تسريب / احتمال: منخفض-متوسط

- • تخفيف + RBAC/MFA/Least privilege + مراجعات دورية + اختبار اختراق / مؤشر.
محاولات وصول مرفوضة مرتفعة أو تغييرات صلاحيات غير مبررة.

5.
أداء الاستعلامات عند توسع البيانات / أثر: بطء لوحات / Chat / احتمال: متوسط

- • تخفيف: تحسين نمذجة + فهارس / Query budgets + Caching + مؤشر: زمن اللوحة ٥ ثوانٍ بشكل متكرر.

6.
مقاومة التغيير التشغيلية / أثر: ضعف البنْيَةِ / احتمال: متوسط

- • تخفيف: تدريب + Champions + Pilot + تحسين UX / مؤشر: انخفاض الاستخدام الأسبوعي عن خط الأساس.

## 17

-
١٠. ٢ إدارة الجودة وضمان الامتثال
- • مراجعات متطلبات/تصميم/أمن في نقاط حوكمة محددة.
- • اختبارات متعددة المستويات مع Traceability متطلب → اختبار → نتيجة → تنبيه.
- • قياسات جودة بيانات دورية (DQ KPIs) والتحسين المستمر.
- • إدارة تغييرات محكومة (Change Control) تمنع الانحراف غير المعتمد.
- • معيار قبول: تقرير جودة شامل قبل Go-Live يثبت اجتياز حالات الاختبار وإغلاق العيوب الحرجة.

- • مدير مشروع (Project Manager)
- • معماري حلول (Solution Architect)
- • قائد بيانات (Data Lead)
- • مهندس تكامل (Integration Engineer)
- • مهندس ذكاء اصطناعي/تعلم آلي (AI/ML Engineer)
- • مهندس أمن سيبراني (Cybersecurity Engineer)
- • مصمم UI/UX
- • مطور/قائد تطبيقات (Application Lead)

- **ضمان الحوكمة:** تجديد بديل (Backup) لكل دور حرچ،
وخطة تواجد خلال Go-Live.
## ١٢،
١٢ افتراضات ومتطلبات التنفيذ
- • توفير وصول معتمد للأنظمة الداخلية ومصادر البيانات،
وفق سياسات الجهة.
- • توفير تعريفات KPI وقوالب التقارير المعتمدة وملاك البيانات.
- • توفير بيئة استضافة معتمدة (أو قرار الاستضافة) مبكراً.
- • تنسيق مبكر مع فرق التحول الرقمي/الأمن لاعتماد نقاط التكامل والصلاحيات.
- • اعتماد قواعد الاستثناء والتصعيد قبل تفعيل التنبيهات في الإنتاج.
## ٢.١٣ إدارة الوثائق ونقل المعرفة
- • توثيق كامل لكل مرحلة: تحليل/تصميم/تطوير/اختبار/نشر.
- • تسليم الكود عبر Git مع سجل إصدارات وإرشادات تشغيل.
- • تسليم: Developer Guide،
Runbook،
دليل التشغيل والصيانة،
وثائق API،
نماذج البيانات،
خطة DR.
- • نقل الملكية الفكرية للكود والوثائق للجهة وفق محاضر استلام.
- • معيار قبول: جلسات نقل معرفة موثقة + تسليم مستودعات Git + وثائق تشغيل قابلة للاستخدام من فريق الجهة.

18

٢,١٤ نموذج الدعم والتشغيل (SLA)

مدة الدعم بعد النشر 3: أشهر ضمن العقد،
مع إمكانية تمديد وفق رغبة الجهة.

- • تصنيف البلاغات (P1–P4) ومؤشرات زمنية:
 
- • P1 (توقف خدمة/تأثير حرِج):
 ◦ زمن الاستجابة: ≥ 30 دقيقة
 ◦ زمن المعالجة/حل مؤقت ≤ 4 ساعات (Workaround):
 ◦ الإغلاق النهائي: ≤ 2 يوم عمل
 
- • P2 (تأثير عالي/تدهور أداء):
 ◦ الاستجابة: ≥ 2 ساعة
 ◦ الحل: ≤ 2 يوم عمل
 
- • P3 (متوسط/خلل وظيفي محدود):
 ◦ الاستجابة: ≥ 1 يوم عمل
 ◦ الحل: ≤ 5 أيام عمل
 
- • P4 (طلب تحسين/استفسار):
 ◦ الاستجابة: ≥ 2 يوم عمل
 ◦ الجدولة: حسب خطة التحسينات ضمن نطاق الدعم

قنوات استقبال البلاغات: بنظام تذاكر رسمي + بريد معتمد.
تقارير دورية: تقرير شهري يتضمن: عدد البلاغات،
الالتزام بـ SLA،
الأسباب الجذرية،
توصيات التحسين.
مراجعات اسبوعية: أول شهر بعد الإطلاق لتثبيت الاستقرار.
معيار قبول: تحقيق التزام SLA ≥ 95% شهرياً خلال فترة الدعم.

- • رفع كفاءة العمليات وتقليل الأعمال اليدوية عبر أنظمة End-to-End.
- • تعزيز الحوكمة والشفافية بمصدر حقيقة واحد وطبقة Semantic KPIs.
- • تمكين القرار المبني على البيانات عبر التحليل الوصفي والتنبؤي القابل للتفسير.
- • تعزيز الابتكار بمساعد تحليلي داخلي (RAG) دون الإدخال بالإقامة أو التدقيق.
- • استدامة التحول عبر تسليم الكود والوثائق ونقل المعرفة،
وتمكين الجهة من التطوير المستقبلي.

القسم الثالث: العرض المالي والتسعيري

٣.١ ملاحظة تنظيمية

تم إعداد هذا القسم وفق نظام المنافسات والمشتريات الحكومية ولوائحه التنفيذية،
وبما يضمن تسعير جميع عناصر نطاق العمل دون غموض أو تجزئة،
وتفادي أي مخاطر متعلقة بإغفال تسعير بعض البنود.
ويقر [Vendor B] أن أي نقص في المستندات النظامية أو الشهادات المطلوبة قد يترتب عليه استبعاد العرض وفق ما تحدده الجهة ولجانها المختصة.

## 19

- ٣.٢ منهجية التسعير
- يعتمد [Vendor B] منهجية تسعير منضبطة تمنع "تحميل بنود غير مستقرة"،
وتضمن شمولية التغطية كما يلي:
 
- • تفصيل التسعير على مستوى المراحل مع بيان ما يشمله كل بند (تحليل/تصميم/تطوير/تكامل/اختبار/نشر/تدريب/دعم).
 
- • عدم تحميل بند على بند آخر بشكل غير واضح.
 
- • تسعير جميع عناصر النطاق بما فيها التشغيل،
المراقبة،
سجلات الجودة،
الاختبارات الأمنية،
ومواد التدريب ضمن المراحل ذات العلاقة.
 
- • توثيق الافتراضات المؤثرة على التكلفة (عدد مصادر P1،
أحجام البيانات،
بيئة الاستضافة) ضمن القسم (٢.١٢) وعدم ترك أي عنصر للتسعير لاحقاً.

٣.٣ التسعير التفصيلي حسب المراحل

جميع المبالغ بالريال السعودي (غير شاملة أي ضرائب/رسوم إن وجدت،
وفق الأنظمة.)
تشمل الأسعار: الموارد البشرية،
التحليل والتصميم،
التطوير،
التوثيق،
الاختبارات،
التشغيل التجريبي،
التدريب،
وتسليم الكود والوثائق.

١) مرحلة التحليل والتصميم
 • الإجمالي: ٩٠٠,٠٠٠ ريال سعودي
 • يشمل: ورش المتطلبات،
جرد المصادر،
DQ baseline،
نموج البيانات،
Prototypes،
تصميم الأمن والتكامل،
وخطط الاختبار.

-
٢) مرحلة التطوير والتنفيذ
 
- • الإجمالي: ١,٤٩٠,٠٠٠ ريال سعودي
 
- • يشمل: تطوير ingestion + warehouse + semantic KPIs + واجهة المحادثة (RAG) + لوحات أساسية + CI/CD مراقبة.

-
٣) مرحلة التكامل

- • الاجمالي: ٣٨٠,٠٠٠ ريال سعودي
- • يشمل: بناء/تفعيل Connectors لمصادر P1،
توثيق Contracts،
اختبارات تكامل،
معالجة mapping والمعرفات.

-
٤) مرحلة الاختبار وضمان الجودة
 
- • الاجمالي: ٣٩٠٠٠٠ ريال سعودي
 
- • يشمل: اختبارات وظيفية/تكامل/اداء/أمن،
Pilot،
UAT،
تقارير عيوب واغلاقها واعادة اختبار.

## 20

-
٥) مرحلة النشر والتشغيل
 
- • الإجمالي: ٢١٠,٠٠٠ ريال سعودي
 
- • يشمل: نشر Prod/DR،
تهيئة الإعدادات،
مراقبة وتشغيل،
Go-Live،
إدارة تغيير.

-
٦) مرحلة التدريب ونقل المعرفة
- • الاجمالي: ٢٧٥,٠٠٠ ريال سعودي
- • يشمل: تدريب المستخدمين الرئيسيين،
تدريب تقني،
مواد تدريبية،
أداة تشغيل وصيانة وتطوير،
جلسات نقل معرفة.

- ٧ (مرحلة الدعم الفني المبني (3 أشهر بعد النشر
- • الإجمالي: ١٩٥,٠٠٠ ريال سعودي
- • يشمل: تشغيل مركز دعم،
تذاكر،
تقارير SLA،
تحسينات عاجلة ضمن النطاق.

٣.٤ الملخص المالي الإجمالي

إجمالي قيمة العرض: ٣,٥٣٠,٠٠٠ ريال سعودي

٥.٣ تأكيد شمولية التسعير

- نؤكد ما يلي:
 
- تم تسعير جميع عناصر نطاق العمل دون استثناء.
 
- لا يوجد أي بند غير مسعر.
 
- لا توجد بنود مشروطة أو مفتوحة أو قابلة للتفسير المالي لاحقاً.
 
- أي عناصر تشغيل/مراقبة/توثيق/اختبارات لازمة لتحقيق المتطلبات مدرجة ضمن المراحل أعلاه.

٣.٦ الالتزام بقواعد إعادة التسعير وصلاحيات لجنة فحص العروض

يقر [Vendor B] ويلتزم صراحةً بالآتي:
أ) استكمال الشهادات/المتطلبات النظامية خلال ١٠ أيام عمل من تاريخ الإشعار في حال كانت ناقصة،
وإلا يحق للجنة استبعاد العرض واتخاذ ما يلزم نظاماً بما في ذلك ما يتعلق بالضمان الابتدائي،
وفق وثائق المنافسة.
ب) الإقرار بأن أي بند غير مسعر قد يؤدي إلى الاستبعاد أو اعتباره محملاً على إجمالي العرض،
وفق ما تقره لجنة فحص العروض.
ج) الإقرار بأنه إذا لم تنفذ البنود المحملة على إجمالي العرض،
يتم تنفيذها على حساب [Vendor B] أو يحتسب متوسط السعر وفق آلية الجهة واحتياجها.
د) الالتزام بـإعادة التسعير للبنود غير المنطقية إذا تبين أنها لا تمثل السعر الحقيقي،
دون تغيير السعر الإجمالي للعرض.

21

والإقرار بأن رفض إعادة التسعير قد يترتب عليه استبعاد العرض وفق ما تقرره لجنة فحص العروض.
كما يلتزم [Vendor B] بتصحيح الأخطاء الحسابية،
وفق ما تقرره لجنة فحص العروض.

٣.٧ الإقرار بمبدأ المفاضلة السعرية وآلية فك التعادل

- • يقرّ [Vendor B] علمه والتزامه بأن:
 
- إذا تساوى عرضان أو أكثر في التقييم الكلي،
تتم الترسية على أقل العروض سعراً.
 
- إذا تساوت الأسعار أيضاً،
فالحجة تُرجّح المنافسة بين العروض المتساوية إذا سمحت الشروط بذلك.
 
- وفي حال عدم النص على التجزئة وتحرزها،
تكون الأولوية في الترسية للمنشآت الصغيرة والمتوسطة المحلية وفق الأنظمة،
وقد تجرى منافسة مغلقة بين العروض المتساوية عند تعذر ذلك.

القسم الرابع: الإقرار الختامي

٤.١ الإقرار الختامي

- • نقر بموجب هذا العرض بما يلي:
- • الالتزام الكامل بدراسة الشروط والمواصفات وما يصدر عنها من إيضاحات رسمية.
- • الالتزام بجميع الأنظمة واللوائح المعمول بها داخل المملكة العربية السعودية.
- • صحة ودقة جميع المعلومات المقدمة في العرض الفني والمالي.
- • جاهزية التنفيذ وفق ما ورد في هذا العرض،
وما يحقق متطلبات الجهة ضمن مدة العقد (18 شهراً) ودعم ما بعد الإطلاق 3 أشهر (وفق (SLA) المحدد.
- • تسليم الكود المصدري والوثائق ونقل المعرفة،
ونقل حقوق الملكية الفكرية للجهة،
وفق محاضر استلام رسمية.

22
